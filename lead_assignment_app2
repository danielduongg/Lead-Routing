import streamlit as st
import pandas as pd
import pickle
from xgboost import XGBClassifier
from sklearn.preprocessing import OrdinalEncoder

# ----------------------------
# Cached model components
# ----------------------------
@st.cache_resource
def load_model_and_encoder():
    # Load your pre-trained model and encoder here (replace with actual file paths if saving to disk)
    # For demo, re-create the logic (normally you'd use joblib/pickle files)
    file_path = "Lead Conversion Data.xlsx"
    xls = pd.ExcelFile(file_path)
    df = xls.parse("Export")

    converted_statuses = {
        'Application Needed', 'Application In', 'AC Enrollment',
        'Started', 'Registered', 'Graduated',
        'Campus - Cond. Accpt. Schol.', 'Campus - Cond. Accpt.', 'Campus - Accpt. Specs.'
    }
    df['Converted'] = df['Record Status'].isin(converted_statuses).astype(int)

    model_df = df[[
        'Lead Source', 'Program of Study', 'State', 'Priority Code',
        'Campaign Code', 'Counselor', 'Counselor Level', 'Lead Created On', 'Converted'
    ]].copy()
    model_df['Lead Created On'] = pd.to_datetime(model_df['Lead Created On'], errors='coerce')
    model_df['Lead Month'] = model_df['Lead Created On'].dt.month
    model_df['Lead Weekday'] = model_df['Lead Created On'].dt.weekday
    model_df.drop(columns=['Lead Created On'], inplace=True)
    model_df.dropna(inplace=True)

    X = model_df.drop(columns=['Converted'])
    y = model_df['Converted']
    encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)
    X_encoded = encoder.fit_transform(X)

    model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', scale_pos_weight=(y == 0).sum() / (y == 1).sum())
    model.fit(X_encoded, y)

    counselors_df = model_df[['Counselor', 'Counselor Level']].drop_duplicates().reset_index(drop=True)
    return model, encoder, counselors_df

# ----------------------------
# Assignment Function
# ----------------------------
def assign_best_counselor(lead_data, model, encoder, counselors_df):
    simulated = counselors_df.copy()
    for key, value in lead_data.items():
        simulated[key] = value

    feature_cols = [
        'Lead Source', 'Program of Study', 'State', 'Priority Code',
        'Campaign Code', 'Counselor', 'Counselor Level', 'Lead Month', 'Lead Weekday'
    ]
    simulated = simulated[feature_cols]
    encoded = encoder.transform(simulated)
    simulated['Predicted Conversion Prob'] = model.predict_proba(encoded)[:, 1]

    return simulated.sort_values(by='Predicted Conversion Prob', ascending=False).head(1)

# ----------------------------
# Streamlit UI
# ----------------------------
st.title("üéØ Lead Assignment Optimizer")

model, encoder, counselors_df = load_model_and_encoder()

with st.form("lead_form"):
    st.subheader("Enter Lead Details")
    lead_source = st.selectbox("Lead Source", options=['WEB', 'AFFILIATE', 'HYBRID'])
    program = st.text_input("Program of Study", "Bachelor of Science in Psychology")
    state = st.text_input("State (e.g., AZ, CA, TX)", "AZ")
    priority = st.selectbox("Priority Code", options=['Cold', '*No Priority Assigned'])
    campaign = st.text_input("Campaign Code", "Direct")
    month = st.slider("Lead Month", 1, 12, 4)
    weekday = st.slider("Lead Weekday (0=Mon)", 0, 6, 1)
    submitted = st.form_submit_button("Find Best Counselor")

    if submitted:
        lead_input = {
            'Lead Source': lead_source,
            'Program of Study': program,
            'State': state,
            'Priority Code': priority,
            'Campaign Code': campaign,
            'Lead Month': month,
            'Lead Weekday': weekday,
        }

        result = assign_best_counselor(lead_input, model, encoder, counselors_df)
        best = result.iloc[0]

        st.success(f"üèÜ Best Counselor: **{best['Counselor']}**")
        st.metric(label="Predicted Conversion Probability", value=f"{best['Predicted Conversion Prob']:.2%}")
